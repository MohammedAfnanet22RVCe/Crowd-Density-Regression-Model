# -*- coding: utf-8 -*-
"""Copy of crowddensity.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CdcBge-81FeIvMZ7oxWRfVVgsZRELiAf
"""

from google.colab import files
uploaded = files.upload()  # Upload kaggle(1).json here

!mkdir -p ~/.kaggle
!mv 'kaggle.json' ~/.kaggle/kaggle.json


!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d tthien/shanghaitech

!unzip -q shanghaitech.zip -d shanghaitech

!ls -R shanghaitech

import os

for root, dirs, files in os.walk(dataset_path):
    print(root)

import os

# PART_B_TRAIN_IMG = "/root/.cache/kagglehub/datasets/tthien/shanghaitech/versions/1/ShanghaiTech/part_B/train_data/images"
# PART_B_TRAIN_GT = "/root/.cache/kagglehub/datasets/tthien/shanghaitech/versions/1/ShanghaiTech/part_B/train_data/ground-truth"
PART_B_TRAIN_IMG = "/content/shanghaitech/ShanghaiTech/part_B/train_data/images"
PART_B_TRAIN_GT  = "/content/shanghaitech/ShanghaiTech/part_B/train_data/ground-truth"

import cv2
import numpy as np
import h5py
from tqdm import tqdm
from glob import glob

from scipy.io import loadmat

import os
import cv2
import scipy.io
import numpy as np

def load_data(img_dir, gt_dir):
    X, y = [], []
    img_files = os.listdir(img_dir)
    img_files.sort()

    for img_file in img_files:
        img_path = os.path.join(img_dir, img_file)
        mat_file = f"GT_{img_file.split('.')[0]}.mat"
        mat_path = os.path.join(gt_dir, mat_file)

        if not os.path.exists(mat_path):
            print(f"Skipping {img_file}: no corresponding .mat file")
            continue

        # Load image
        img = cv2.imread(img_path)
        if img is None:
            print(f"Skipping {img_file}: could not load image")
            continue

        X.append(img)

        # Load annotation count
        mat = scipy.io.loadmat(mat_path)
        annPoints = mat["image_info"][0][0][0][0][0]
        y.append(len(annPoints))  # Count of people

    return np.array(X), np.array(y)

from sklearn.model_selection import train_test_split
X_train, y_train = load_data(PART_B_TRAIN_IMG, PART_B_TRAIN_GT)
X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2)

import tensorflow as tf
from sklearn.model_selection import train_test_split

# Step 1: Load actual data (assuming you defined load_data() earlier)
X_all, y_all = load_data(PART_B_TRAIN_IMG, PART_B_TRAIN_GT)

# Step 2: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2)

# Step 3: Resize images to (995, 421)
X_train_resized = tf.image.resize(X_train, [995, 421])
X_test_resized = tf.image.resize(X_test, [995, 421])

import tensorflow as tf

model = tf.keras.Sequential([
    tf.keras.layers.Input(shape=(995, 421, 3)),
    tf.keras.layers.Rescaling(1./255),
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(1)  # Output: crowd count
])

model.compile(optimizer='adam', loss='mse', metrics=['mae'])
model.summary()

# Convert resized tensors to NumPy arrays (required by model.fit)
X_train_resized = tf.image.resize(X_train, [995, 421]).numpy()

# Train the model
model.fit(X_train_resized, y_train, epochs=100, batch_size=4, validation_split=0.2)

import matplotlib.pyplot as plt
import tensorflow as tf

# Pick one test image
img = X_train[2]
true_count = y_train[2]

# Resize image to model input size
img_resized = tf.image.resize(img, [995, 421]).numpy()

# Predict crowd count
pred_count = model.predict(img_resized.reshape(1, 995, 421, 3))[0][0]

# Show original image (optional: resize for display only)
plt.imshow(img.astype('uint8'))  # or `img_resized.astype('uint8')` if you prefer
plt.title(f"Predicted: {pred_count:.2f}, Actual: {true_count}")
plt.axis("off")
plt.show()

# Save entire model (architecture + weights + optimizer state)
model.save("resized_model_small.h5")

from google.colab import files
files.download('resized_model.h5')

from google.colab import files
uploaded = files.upload()  # Upload kaggle(1).json here

import matplotlib.pyplot as plt
import tensorflow as tf
import numpy as np
from PIL import Image

# Load uploaded image
image_path = 'IMG20250614104238.jpg'  # Use the exact filename you uploaded
img = Image.open(image_path).convert('RGB')

# Resize to model input size (995, 421)
img_resized = img.resize((421, 995))  # (width, height)

# Convert to numpy and normalize
img_array = np.array(img_resized).astype('float32') / 255.0

# Add batch dimension
input_tensor = np.expand_dims(img_array, axis=0)  # Shape: (1, 995, 421, 3)

# Predict
pred_count = (model.predict(input_tensor)[0][0])

# Show result
plt.imshow(img)
plt.title(f"Predicted Crowd Count: {pred_count/10:.2f}")
plt.axis("off")
plt.show()